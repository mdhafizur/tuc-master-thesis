\section{Agent Implementation}
\label{sec:impl-agents}

This section details the concrete implementation of each agent in the Invox system, covering their API contracts, processing logic, and integration patterns. Each agent exposes well-defined TypeScript interfaces and follows consistent error handling patterns. The implementation is designed to be domain-agnostic, supporting arbitrary template schemas across healthcare, manufacturing, administrative, and other domains.

\subsection{Speech-to-Text (STT) Agent}
\label{subsec:impl-stt}

The STT agent provides a single entry point \texttt{transcribeForm} that converts audio inputs to structured transcripts using OpenAI's Whisper model.

Listing~\ref{lst:stt-api} defines the input and output schema for the STT agent.

\begin{lstlisting}[language=Java, caption={STT agent API contract}, label={lst:stt-api}]
interface TranscribeInput {
  file: {
    base64: string;
    mimetype: "audio/wav" | "audio/mpeg" | "audio/m4a";
    originalname: string;
  };
}

interface TranscribeResponse {
  transcript: string;
  language: string;
  durationInSeconds: number;
  segments?: Array<{
    start: number;
    end: number;
    text: string;
    confidence?: number;
  }>;
}
\end{lstlisting}

The \texttt{TranscribeInput} interface encapsulates the uploaded audio file as a Base64-encoded payload with an associated MIME type and original filename. The interface \texttt{TranscribeResponse} returns the full transcription in \texttt{transcript}, the detected language as an ISO 639-1 code in \texttt{language}, and the total audio duration in seconds via \texttt{durationInSeconds}. The optional \texttt{segments} array provides time-aligned fragments of the transcription that can be used by downstream components for error analysis and selective verification.

\textbf{Implementation.} The agent decodes Base64 audio data into buffers and invokes the Whisper API via the Vercel AI SDK. Long audio files (>25\,MB or >10\,minutes) are automatically chunked with a 10\% overlap to preserve context at segment boundaries. When available, the agent returns time-aligned segments with confidence scores, enabling downstream agents to trace extracted values back to specific audio regions. Failed transcriptions (e.g., due to excessive noise or unsupported formats) result in structured errors that the orchestrator can handle gracefully, either by requesting re-recording or by falling back to manual text entry.

\textbf{Configuration.} Temperature is set to 0 to obtain deterministic output across repeated runs. Language detection is performed automatically unless explicitly overridden by the client. Voice activity detection (VAD) is applied to filter out silence and non-speech segments, which improves both transcription quality and processing efficiency.

\subsection{Retrieval-Augmented Generation (RAG) Agent}
\label{subsec:impl-rag}

The RAG agent implements semantic search over historical templates through the \texttt{getFewShotsFromTranscript} function, which retrieves contextually relevant examples to guide the information extraction process.

Listing~\ref{lst:rag-api} defines the input and output schema for the RAG agent.

\begin{lstlisting}[language=Java, caption={RAG agent API contract}, label={lst:rag-api}]
interface RAGInput {
  transcript: string;
  fields: FormTemplateField[];
  k?: number;
}

interface FewShot {
  text: string;
  expected: Record<string, {
    value: unknown | null;
    evidence?: { transcriptSnippet?: string };
  }>;
}
\end{lstlisting}

The \texttt{RAGInput} interface specifies the data required for semantic retrieval. The \texttt{transcript} field contains the input text used for similarity search, while \texttt{fields} holds the target form schema as an array of \texttt{FormTemplateField} objects. The optional parameter \texttt{k} controls how many example instances are retrieved for few-shot prompting; if omitted, a default of five examples is used to keep prompt size manageable.

The \texttt{FewShot} interface represents a single retrieved example. The \texttt{text} property contains a truncated version of a historical transcript, and the \texttt{expected} map associates each field identifier with its normalized value. Each entry in \texttt{expected} may also contain \texttt{evidence} in the form of a \texttt{transcriptSnippet}, which highlights the segment of the original transcript that supports the stored value.

\textbf{Implementation.} The agent generates dense vector embeddings using OpenAI's \texttt{text-embedding-3-large} model. A key implementation detail is the embedding generation process: the input text is prefixed with \texttt{templateId=\${TEMPLATE\_ID}} to create template-aware embeddings that improve retrieval relevance within specific template contexts. The agent then performs k-nearest neighbor search using cosine similarity in OpenSearch with the \texttt{knn\_score} script. The search query filters results by template ID to ensure schema compatibility and uses a \texttt{script\_score} approach for efficient vector similarity computation.

\textbf{Result processing.} Retrieved documents undergo post-processing where transcript texts are truncated to a fixed maximum length (default: 1200 characters) to maintain prompt efficiency. The \texttt{toExpectedShape} function maps raw database results to the expected field schema, ensuring that only fields present in the current template schema are included in the output.

\textbf{Error handling.} The implementation includes robust error handling for embedding generation failures and OpenSearch connectivity issues. If retrieval fails, the system gracefully falls back to zero-shot extraction, ensuring continuous operation despite temporary infrastructure problems.

\subsection{Information Extraction (IE) Agent}
\label{subsec:impl-ie}

The IE agent implements four extraction strategies through unified functions corresponding to S1--S4. All strategies share a common preprocessing pipeline and differ only in their orchestration of LLM calls.

Listing~\ref{lst:ie-api} defines the core input and output schema for the IE agent.

\begin{lstlisting}[language=Java, caption={IE agent core API contract}, label={lst:ie-api}]
interface IEInput {
  oldTranscript?: string;
  newTranscript: string;
  fields: FormTemplateField[];
  currentValues?: Record<string, CurrentFieldValue>;
  strategy: "S1" | "S2" | "S3" | "S4";
  fewShots?: RAGOutput["examples"];
  locale?: string;
  timezone?: string;
  templateId?: string;
}

interface IEOutput {
  filled: Record<string, FilledField>;
  model: string;
  confidence?: Record<string, number>;
}
\end{lstlisting}

The \texttt{IEInput} interface captures all information required for a single extraction step. The \texttt{newTranscript} field holds the latest user input and is treated as the primary source of new information, while \texttt{oldTranscript} optionally provides previous context for incremental updates. The \texttt{fields} array contains the target template schema as \texttt{FormTemplateField} definitions. The optional \texttt{currentValues} map stores previously filled field values, including metadata about their origin and lock status. The \texttt{strategy} parameter selects one of the four extraction strategies (S1--S4). Optional \texttt{fewShots} provide retrieved examples from the RAG agent, and \texttt{locale}, \texttt{timezone}, and \texttt{templateId} supply environment and logging metadata.

The \texttt{IEOutput} interface aggregates the final extraction result. The \texttt{filled} map associates each field identifier with a \texttt{FilledField} object, while \texttt{model} records the model identifier or combination of models used (e.g., for ensemble strategies). The optional \texttt{confidence} map stores per-field confidence scores normalized to the interval \([0,1]\). The detailed structure of \texttt{CurrentFieldValue} and \texttt{FilledField} is provided in Appendix~\ref{appendix:detailed-implementation}.

\textbf{Strategy implementations.}

\paragraph{S1: Single-Pass Full-Input (\texttt{singleLlmAllField})}
This strategy constructs a comprehensive prompt requesting all template fields simultaneously. The prompt includes task instructions emphasizing extraction from \texttt{newTranscript} only, few-shot examples from the RAG agent (up to three examples showing input--output mappings), field definitions with type constraints and allowed options for enum fields, current field values with their lock status, and both old and new transcripts (old for context, new for extraction).

The agent uses Zod schema validation to ensure type-safe outputs. Dates must match the \texttt{YYYY-MM-DD} format, numbers must be finite, and enum values must belong to the predefined set. The LLM is instructed to return a JSON object with one key per field identifier. Post-processing normalizes values (for example, joining arrays to comma-separated strings for multi-value fields and trimming whitespace) and applies lock-aware merging: if a field is locked or if the new transcript does not mention a field, the current value is preserved.

\paragraph{S2: Iterative Single-Field (\texttt{singleLlmOneField})}
This strategy processes each field independently using a field-specific prompt. For each field, the agent filters RAG examples to include only those that populated this particular field, constructs a focused prompt with field-specific guidelines and type constraints along with one or two relevant examples, calls the LLM with a schema of the form \texttt{\{value, confidence\}}, normalizes the returned value according to the field type, and applies lock-aware update logic.

Fields are processed in parallel using \texttt{Promise.all}, which reduces wall-clock latency on multi-core systems. Each field call is wrapped in its own error boundary: if extraction for one field fails (for example, due to an API timeout or parsing error), the remaining fields proceed unaffected and the failed field retains its current value. This isolation improves robustness compared to S1, where a single malformed response can invalidate the entire output.

\paragraph{S3: Multi-LLM Consensus Full-Input (\texttt{dualLlmAllField})}
S3 runs two models in parallel---GPT-4 and Gemini~2.0 Flash by default---each generating a complete template using the same prompt as S1. The two candidate outputs are then passed to a verification agent that implements consensus logic with rule-based checks to validate that locked fields were not overwritten, enum values remain within their allowed set, and dates are parseable.

LLM-based reconciliation uses a judge model (GPT-4o-mini by default) that compares the two candidate outputs field-by-field and selects one of four decisions: \texttt{gpt} (use GPT's value), \texttt{gemini} (use Gemini's value), \texttt{merge} (combine both values for multi-value text fields), or \texttt{keep\_current} (neither candidate is reliable; preserve the existing value). The verifier prompt includes both candidate outputs, the transcript, and field-level metadata (type, required status, current value). For multi-value fields, the merge operation deduplicates and quality-filters entries, discarding empty strings or placeholders.

\paragraph{S4: Multi-LLM Consensus Per-Field (\texttt{multiLlmOneField})}
S4 combines the granularity of S2 with the robustness of S3. For each field, the agent runs GPT and Gemini in parallel with field-specific prompts, analogous to S2, and then passes both candidate values to a per-field verifier. The verifier applies the same decision logic as in S3 but focuses on a single field at a time, which reduces prompt size and often improves decision quality. The final value is returned together with an aggregated confidence score.

This strategy has the highest computational cost---\emph{(number of fields)}~$\times$~\emph{(number of models)} LLM calls---but offers maximum reliability by isolating errors at the field level and leveraging ensemble diversity for each slot.

\textbf{Shared preprocessing.} All strategies share common logic for incremental updates (only \texttt{newTranscript} is treated as the source of new information), lock enforcement (fields marked \texttt{locked = true} are never overwritten), change detection (the \texttt{changed} flag is set only if the final value differs from the \texttt{currentValue}), and type-specific normalization to ensure consistent representations across strategies.

\subsection{Consistency Formatting (CF) Agent}
\label{subsec:impl-cf}

The CF agent provides \texttt{normalizeValueForField} for deterministic value standardization based on field type. Its purpose is to turn potentially noisy or ambiguous model outputs into canonical representations that can be stored and compared reliably.

The CF agent applies a set of type-specific transformations. For date fields, natural-language expressions (e.g., ``March 3, 1992'') are converted into ISO format (\texttt{YYYY-MM-DD}). For numeric fields, textual inputs such as ``25 people'' are reduced to finite numbers (e.g., \texttt{25}). Enum fields are checked against the list of allowed options in a case-insensitive manner, and invalid values are rejected. List-like or multi-value fields are converted into compact, human-readable strings (e.g., ``A, B'') by filtering out null, empty, or placeholder entries and joining the remainder.

For text and textarea fields, CF trims leading and trailing whitespace and applies Unicode normalization (NFC form) to ensure consistent representation of accented characters and similar multi-codepoint symbols across different input methods.

\textbf{Implementation.} The transformations are implemented using standard libraries (e.g., Luxon for date parsing) and simple regex-based extraction for numbers, combined with case-insensitive matching for enum validation. Ambiguous values that cannot be normalized deterministically (e.g., ``\texttt{3/4/92}'' with unclear month/day order) are not silently corrected: instead, they are flagged so that the verification agent can mark the affected field for clarification or manual review. The CF agent is intentionally non-stochastic: given the same input, it always produces the same output. The concrete helper functions are listed in Appendix~\ref{app:cf-impl}.

\subsection{Verification Agent (VER)}
\label{subsec:impl-ver}

The verification agent serves as the final decision layer before values are shown to the user or persisted. It handles both single-model outputs (via \texttt{runVerifier}) and multi-model consensus for S3/S4 (via \texttt{runEnsembleVerifier}). Inputs include candidate field values, the template schema, the combined transcript, and any previously locked or prefilled values; outputs contain the consolidated field map, calibrated confidence scores, and issue flags.

\textbf{Consensus logic (S3/S4).} For ensemble strategies, VER compares candidates from multiple models using a judge LLM. The judge receives the competing values, relevant transcript excerpts, schema rules, and lock status, and returns a structured per-field decision (choose GPT, choose Gemini, merge, or keep the existing value). If merging is selected, normalization and deduplication ensure schema-compliant output.

\textbf{Single-model verification (S1/S2).} When only one candidate is available, VER performs deterministic checks such as required-field completeness, type validation, and basic cross-field consistency. Low-confidence or weakly grounded values are flagged for manual review, while stronger inconsistencies trigger clarification prompts.

Overall, VER standardizes outputs across strategies, enforces schema correctness, and records the rationale behind each decision to support transparency and user trust.

\subsection{Agent Orchestration}
\label{subsec:impl-orchestration}

The \texttt{Orchestrator} class coordinates agent execution through typed procedure calls exposed via tRPC endpoints. The orchestrator is strategy-aware: it selects the appropriate IE function (S1--S4) based on client configuration and manages the end-to-end pipeline flow.

Conceptually, the pipeline executes in six steps. First, the orchestrator performs optional transcription using the STT agent when audio is provided; otherwise, it wraps the raw text and language into a synthetic transcript object. Second, it invokes the RAG agent to retrieve few-shot examples conditioned on the transcript, template fields, and template identifier. Third, it calls the IE agent using the strategy specified by the client, passing along the transcript, schema, current values, and retrieved examples.

In the fourth step, the CF agent applies deterministic normalization to the extracted values, ensuring consistent formatting across fields and runs. Fifth, the verification agent checks completeness and consistency, potentially adjusting field-level confidences and emitting structured issues. Finally, the orchestrator inspects the verification result for issues that require re-querying (e.g., fields marked with the \texttt{"requery"} action). If necessary, it can trigger an additional IE+VER cycle using hints from the verifier before returning the final \texttt{FinalTemplate} object to the client.

The complete TypeScript implementation of the orchestration logic, including the \texttt{processTemplate} method and the \texttt{runStrategy} helper, is provided in Appendix~\ref{app:orchestrator-impl}.
