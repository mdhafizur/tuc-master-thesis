Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm for grounding LLM outputs in external knowledge without retraining. Surveys on augmented language models highlight RAG's ability to improve factual accuracy and reduce hallucination by conditioning generation on retrieved context \cite{mialon2023augmented}.

In the domain of secure coding, several works leverage RAG to incorporate vulnerability knowledge, secure coding guidelines, and historical fixes. RESCUE proposes a hierarchical retrieval framework that combines vulnerability taxonomies with code examples to improve secure code generation \cite{shi2025rescue}. Evaluation results show improved security metrics compared to LLM-only baselines. However, RESCUE focuses on code generation rather than interactive vulnerability detection and assumes access to cloud-based or centralized resources.

Systematic literature reviews emphasize that while RAG improves detection consistency and security grounding, most existing approaches do not consider privacy-preserving local deployment or IDE-native interaction \cite{basic2025slr}. As a result, the practical applicability of RAG-based secure coding systems in industrial environments remains limited.
