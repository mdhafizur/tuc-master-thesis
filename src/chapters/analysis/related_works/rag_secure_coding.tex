Retrieval-Augmented Generation (RAG) is a general paradigm for grounding language model outputs in external knowledge without retraining. In RAG, a retriever selects relevant documents for a given query and the generator conditions on those documents when producing an answer \cite{lewis2020rag}. Retrieval can be implemented with lexical scoring functions such as BM25 \cite{robertson2009bm25} or with dense retrieval based on semantic embeddings. Dense retrieval approaches such as DPR and retrieval-augmented pretraining (REALM) motivate this design by showing that semantic retrieval can provide effective context for generation \cite{karpukhin2020dpr,guu2020realm}. Survey work further highlights RAG as a practical way to reduce hallucination and improve factuality \cite{mialon2023augmented,ji2023hallucination}.

In secure coding settings, the retrieved context typically corresponds to vulnerability taxonomies (e.g., CWE), secure coding guidelines (e.g., OWASP cheat sheets), and historical vulnerability examples. This is a natural fit for vulnerability detection and repair because many issues are best explained by mapping code patterns to known weakness classes and well-established mitigations \cite{mitreCWE,owaspCheatSheets,owaspTop10_2021}. By grounding the model in such sources, the system can improve consistency (R1) and explanation quality (R3), while reducing unsupported guesses.

Implementation-wise, RAG depends on embedding models and efficient nearest-neighbor search. Sentence-level embedding methods such as Sentence-BERT are commonly used to map text into vector space \cite{reimers2019sentencebert}. Approximate nearest-neighbor indices such as HNSW provide high recall with practical latency \cite{malkov2018hnsw}, and libraries such as FAISS popularized large-scale similarity search in practice \cite{johnson2017faiss}. In Code Guardian, these ideas are realized through local embeddings and a persistent HNSW vector store to keep retrieval on-device and compatible with IDE latency constraints.
