\section{Results: LLM-Only Configuration}
\label{sec:eval-llm-only}

This section reports results for Code Guardian when operating without retrieval augmentation. The goal is to establish a baseline for detection quality and latency when the model receives only the analyzed code and strict JSON-output constraints.

\subsection*{Detection Quality}

Table~\ref{tab:eval-llm-only} summarizes precision, recall, and F1 score for the LLM-only configuration using the merged thesis result set (113 vulnerable + 15 secure/negative cases). These values are reported per model because local models show distinct precision/recall trade-offs and false-positive behavior.

\begin{table}[H]
  \centering
  \caption{LLM-only evaluation metrics on the merged thesis result set.}
  \label{tab:eval-llm-only}
  \small
  \begin{tabular}{lccccc}
    \toprule
    Model & Precision (\%) & Recall (\%) & F1 (\%) & FPR (\%) & Parse rate (\%) \\
    \midrule
    \texttt{gemma3:1b} & 45.31 & 25.66 & 32.77 & 100.00 & 100.00 \\
    \texttt{gemma3:4b} & 50.59 & 62.83 & 56.05 & 100.00 & 100.00 \\
    \texttt{qwen3:4b} & 48.74 & 62.83 & 54.90 & 100.00 & 100.00 \\
    \texttt{qwen3:8b} & 54.06 & 62.83 & 58.12 & 26.67 & 100.00 \\
    \texttt{CodeLlama:latest} & 38.42 & 46.02 & 41.88 & 100.00 & 100.00 \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection*{Latency}

For interactive usage, response time is critical. Table~\ref{tab:eval-llm-only-latency} reports median and mean latency per analysis call for each model under the evaluation harness.

\begin{table}[H]
  \centering
  \caption{LLM-only latency metrics.}
  \label{tab:eval-llm-only-latency}
  \small
  \begin{tabular}{lcc}
    \toprule
    Model & Median (ms) & Mean (ms) \\
    \midrule
    \texttt{gemma3:1b} & 333 & 626 \\
    \texttt{gemma3:4b} & 1932 & 2290 \\
    \texttt{qwen3:4b} & 1178 & 1440 \\
    \texttt{qwen3:8b} & 1548 & 1909 \\
    \texttt{CodeLlama:latest} & 1314 & 1782 \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection*{Discussion}

The LLM-only results show heterogeneous behavior across model families. \texttt{qwen3:8b} provides the strongest LLM-only F1 (58.12\%) and the lowest LLM-only FPR (26.67\%), while remaining slower than smaller models. \texttt{gemma3:4b} and \texttt{qwen3:4b} reach similar recall (62.83\%) but over-warn heavily on secure samples (FPR 100\%). \texttt{gemma3:1b} is fastest but lower-recall than larger configurations.
